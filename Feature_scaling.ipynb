{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c6d89b3-fb16-42fb-9619-06fbf9a75695",
   "metadata": {},
   "source": [
    "# What is feature scaling?\n",
    "\n",
    "Feature Scaling is a technique to standardize the independent features present in the data. It is performed during the data pre-processing to handle highly varying values. If feature scaling is not done then machine learning algorithm tends to use greater values as higher and consider smaller values as lower regardless of the unit of the values.\n",
    "\n",
    "Feature scaling is a preprocessing technique that transforms feature values to a similar scale, ensuring all features contribute equally to the model.\n",
    "\n",
    "They help improve model performance, enhance convergence and reduce biases. \n",
    "\n",
    "Machine learning algorithms like linear regression, logistic regression, neural network, PCA (principal component analysis), etc., that use gradient descent as an optimization technique require data to be scaled.To ensure that the gradient descent moves smoothly towards the minima and that the steps for gradient descent are updated at the same rate for all the features, we scale the data before feeding it to the model.\n",
    "\n",
    "Distance algorithms like KNN, K-means clustering, and SVM(support vector machines) are most affected by the range of features. This is because, behind the scenes, they are using distances between data points to determine their similarity.\n",
    "\n",
    "Tree-based algorithms, on the other hand, are fairly insensitive to the scale of the features.\n",
    "\n",
    "# Different techniques which are used to perform feature scaling :\n",
    "\n",
    "1. Standardization : When there are outliers in variable/data\n",
    "\n",
    "   \n",
    "   - This method of scaling is basically based on the central tendencies and variance of the data.\n",
    "   - Standardization can be helpful in cases where the data follows a Gaussian distribution. \n",
    "   - Transforms data to have a mean of 0 and a standard deviation of 1 (also known as z-score scaling ie. -3 to 3 range).\n",
    "   - Formula - Xscaled = (Xi - Xmean)/standard deviation.\n",
    "   - Less sensitive to outliers than normalization.\n",
    "   - It is useful when the feature distribution is Normal or Gaussian.\n",
    "   - It is a often called as Z-Score Normalization. \n",
    "\n",
    "3. Normalization : When there are no ouliers in variable/data\n",
    "\n",
    "   - This scales the range to [0, 1] or sometimes [-1, 1].\n",
    "   - Formula : X_new = (X - X_mean)/(X_max - X_min)\n",
    "   - Normalization is useful when there are no outliers as it cannot cope up with them.\n",
    "   - It is useful when we don’t know about the distribution\n",
    "   - It is a often called as Scaling Normalization\n",
    "\n",
    "4. MinMaxcsaler :\n",
    "\n",
    "   - Formula  : X_new = (X-X_min)/(X_max - X_min)\n",
    "   - the data will range after scaling between 0 to 1.\n",
    "\n",
    "5. RobustScaler :\n",
    "\n",
    "   - In this method of scaling, we use two main statistical measures of the data : Median and Inter-Quartile Range.\n",
    "   -  Formula : X_new = (X-Xmedian) / IQR\n",
    "\n",
    "# Image scaling\n",
    "1. Normalization : by normalization, mean dividing pixel values by 255.\n",
    "\n",
    "   datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "2. Standardization : Standardization means subtracting the mean value of pixels and then dividing by standard deviation.\n",
    "\n",
    "   datagen = tf.keras.preprocessing.image.ImageDataGenerator(samplewise_center=True, samplewise_std_normalization=True)\n",
    "\n",
    "3. Using opencv for scaling images :\n",
    "\n",
    "   import cv2\n",
    "\n",
    "   bigger = cv2.resize(image, (1050, 1610))\n",
    "\n",
    "   **Rescaling Pixel Values:**\n",
    "\n",
    "    import cv2\n",
    "    Img = cv2.imread ('image.jpg')\n",
    "    normalized = img / 255.0\n",
    "\n",
    "4. Histogram Equalization: This spreads out pixel intensities over the whole range to improve contrast. This works well for images with low contrast where pixel values are concentrated in a narrow range. It can be applied with OpenCV using:\n",
    "\n",
    "   eq_img = cv2.equalizeHist(img)\n",
    "\n",
    "5. Normalizing : It means to have zero mean and unit variance. This will center the image around zero with a standard deviation of 1.This can be done by subtracting the mean and scaling to unit variance:\n",
    "\n",
    "    mean, std = cv2.meanStdDev (img)\n",
    "    std_img = (img - mean) / std\n",
    "\n",
    "6. Some popular noise reduction techniques include:\n",
    "    - Gaussian blur — Uses a Gaussian filter to blur the image and reduce high frequency noise.\n",
    "    - Median blur — Replaces each pixel with the median of neighboring pixels. Effective at removing salt and pepper noise.\n",
    "    - Bilateral filter — Blurs images while preserving edges. It can remove noise while retaining sharp edges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
